{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46c2a5bd",
   "metadata": {},
   "source": [
    "## Описание набора данных\n",
    "Для выполнения лабораторной работы, как и в предыдущих лабораторных, используется набор данных **Automobile Dataset** (файл `Automobile.csv`, источник: Kaggle – Automobile Dataset).\n",
    "\n",
    "Данные содержат информацию о характеристиках автомобилей: происхождении, мощности двигателя, массе, ускорении, объёме двигателя, расходе топлива и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72c0c62",
   "metadata": {},
   "source": [
    "## 1. Импорт библиотек и загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d0660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv(\"Automobile.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c92d142",
   "metadata": {},
   "source": [
    "## 2. Оценка пригодности датасета для классификации\n",
    "\n",
    "### 2.1. Выбор целевого атрибута (метки)\n",
    "В датасете есть категориальный атрибут **origin**, который отражает регион происхождения автомобиля.\n",
    "Он принимает три значения: `usa`, `japan`, `europe`. Следовательно, `origin` подходит как **целевая метка класса**.\n",
    "\n",
    "### 2.2. Проверка сбалансированности классов\n",
    "Посчитаем количество объектов каждого класса и их долю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b176ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = data[\"origin\"].value_counts()\n",
    "class_share = data[\"origin\"].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Количество по классам:\\n\", class_counts, \"\\n\")\n",
    "print(\"Доли классов (%):\\n\", class_share.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69657ed",
   "metadata": {},
   "source": [
    "**Вывод по сбалансированности:**\n",
    "Класс `usa` доминирует (примерно ~60%+), классы `japan` и `europe` представлены заметно меньше.\n",
    "Это означает, что датасет **несбалансирован**, поэтому при оценке качества важно смотреть не только Accuracy,\n",
    "но и **macro Precision/Recall/F1**, так как они учитывают качество по каждому классу равновесно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c9706e",
   "metadata": {},
   "source": [
    "## 3. Очистка и подготовка данных\n",
    "\n",
    "### 3.1. Удаление дубликатов\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caff01a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ddde04",
   "metadata": {},
   "source": [
    "### 3.2. Проверка пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23377b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Пропуски по столбцам:\\n\", data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e1a53a",
   "metadata": {},
   "source": [
    "В наборе данных встречаются пропуски (чаще всего в `horsepower`).\n",
    "Для корректного обучения моделей пропуски будут заполнены медианой (импутация)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c38ea0a",
   "metadata": {},
   "source": [
    "## 4. Подготовка признаков и целевого столбца\n",
    "\n",
    "В качестве признаков берем числовые характеристики.\n",
    "Столбец name исключаем (это текстовый идентификатор модели и не является полезным числовым признаком)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5b40b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"origin\", \"name\"])\n",
    "y = data[\"origin\"]\n",
    "\n",
    "print(\"Форма X:\", X.shape)\n",
    "print(\"Классы y:\", y.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28361a7",
   "metadata": {},
   "source": [
    "## 5. Разделение на обучающую и тестовую выборки\n",
    "Данные делятся на train/test в пропорции 70/30.\n",
    "Используем `stratify=y`, чтобы доли классов в train и test были одинаковыми."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabe27ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71067bd",
   "metadata": {},
   "source": [
    "## 6. Обучение модели kNN\n",
    "\n",
    "Для kNN важно масштабирование признаков (StandardScaler), иначе признаки с большим масштабом (например `weight`)\n",
    "будут доминировать при вычислении расстояний.\n",
    "\n",
    "Pipeline для kNN:\n",
    "- заполнение пропусков медианой\n",
    "- стандартизация признаков\n",
    "- классификатор kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68683813",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", KNeighborsClassifier(n_neighbors=7, weights=\"distance\"))\n",
    "])\n",
    "\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f16df8",
   "metadata": {},
   "source": [
    "## 7. Обучение модели дерева решений\n",
    "\n",
    "Дерево решений не требует масштабирования.\n",
    "Для уменьшения переобучения зададим ограничения: `max_depth` и `min_samples_leaf`.\n",
    "\n",
    "Pipeline для дерева:\n",
    "- заполнение пропусков медианой\n",
    "- DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ae392",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"clf\", DecisionTreeClassifier(\n",
    "        random_state=42,\n",
    "        max_depth=5,\n",
    "        min_samples_leaf=5\n",
    "    ))\n",
    "])\n",
    "\n",
    "tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13683783",
   "metadata": {},
   "source": [
    "## 8. Оценка качества моделей\n",
    "\n",
    "Будем считать:\n",
    "- Accuracy\n",
    "- Precision / Recall / F1 (macro и weighted)\n",
    "- ROC-AUC (для многоклассовой классификации через One-vs-Rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e1b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    p_macro, r_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        y_test, y_pred, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    p_w, r_w, f1_w, _ = precision_recall_fscore_support(\n",
    "        y_test, y_pred, average=\"weighted\", zero_division=0\n",
    "    )\n",
    "\n",
    "    # ROC-AUC для многоклассовой классификации (OvR)\n",
    "    classes = model.classes_\n",
    "    y_bin = label_binarize(y_test, classes=classes)\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "\n",
    "    roc_auc = roc_auc_score(\n",
    "        y_bin, y_proba,\n",
    "        average=\"macro\",\n",
    "        multi_class=\"ovr\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision_macro\": p_macro,\n",
    "        \"Recall_macro\": r_macro,\n",
    "        \"F1_macro\": f1_macro,\n",
    "        \"F1_weighted\": f1_w,\n",
    "        \"ROC_AUC_macro\": roc_auc\n",
    "    }, y_pred\n",
    "\n",
    "knn_metrics, knn_pred = evaluate(knn_model, X_test, y_test)\n",
    "tree_metrics, tree_pred = evaluate(tree_model, X_test, y_test)\n",
    "\n",
    "knn_metrics, tree_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02c56b7",
   "metadata": {},
   "source": [
    "### 8.1. Отчёт классификации (Precision/Recall/F1 по каждому классу)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebe5abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"kNN classification report:\\n\")\n",
    "print(classification_report(y_test, knn_pred))\n",
    "\n",
    "print(\"\\nDecision Tree classification report:\\n\")\n",
    "print(classification_report(y_test, tree_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de2b35c",
   "metadata": {},
   "source": [
    "### 8.2. Сравнительная таблица метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab70247",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame([knn_metrics, tree_metrics], index=[\"kNN\", \"Decision Tree\"])\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a8ba31",
   "metadata": {},
   "source": [
    "## 9. ROC-кривые (One-vs-Rest) для kNN и дерева решений\n",
    "\n",
    "Так как классов три, строим ROC отдельно для каждого класса (OvR):\n",
    "- рассматриваем класс как \"1\", остальные как \"0\"\n",
    "- строим ROC по вероятностям predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba374c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiclass_roc(model, X_test, y_test, title):\n",
    "    classes = model.classes_\n",
    "    y_bin = label_binarize(y_test, classes=classes)\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "\n",
    "    plt.figure(figsize=(7,5))\n",
    "    for i, cls in enumerate(classes):\n",
    "        fpr, tpr, _ = roc_curve(y_bin[:, i], y_proba[:, i])\n",
    "        plt.plot(fpr, tpr, label=f\"{cls}\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_multiclass_roc(knn_model, X_test, y_test, \"ROC-кривые (OvR) — kNN\")\n",
    "plot_multiclass_roc(tree_model, X_test, y_test, \"ROC-кривые (OvR) — Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1f2476",
   "metadata": {},
   "source": [
    "## 10. Объяснение результатов\n",
    "\n",
    "1) **Дерево решений** часто показывает более высокие значения Accuracy и F1, потому что:\n",
    "- умеет находить нелинейные правила (например, комбинации `weight`, `cylinders`, `displacement`),\n",
    "- автоматически выделяет информативные пороги по признакам.\n",
    "\n",
    "2) **kNN** зависит от расстояний в пространстве признаков:\n",
    "- требует стандартизации,\n",
    "- может ошибаться при перекрытии классов (когда автомобили разных регионов имеют похожие характеристики),\n",
    "- при дисбалансе чаще “тянется” к доминирующему классу `usa`.\n",
    "\n",
    "3) **Почему важно смотреть macro-F1:**\n",
    "Из-за доминирования `usa` метрика Accuracy может выглядеть высокой даже тогда,\n",
    "когда модель хуже распознаёт `japan` и `europe`.\n",
    "Macro-метрики показывают среднее качество по классам без учета их размера.\n",
    "\n",
    "4) **ROC-AUC:**\n",
    "ROC-AUC (OvR) показывает, насколько хорошо модель ранжирует вероятности классов.\n",
    "Даже при ошибках в жёстком выборе класса (argmax), ROC-AUC может быть высоким,\n",
    "если модель в целом корректно “отличает” классы по вероятностям."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff36a032",
   "metadata": {},
   "source": [
    "## Итоговый вывод о пригодности датасета\n",
    "\n",
    "Датасет **пригоден для задачи классификации**, потому что:\n",
    "- есть естественная целевая метка `origin` (3 класса),\n",
    "- есть набор числовых признаков, потенциально связанных с происхождением автомобиля.\n",
    "\n",
    "Однако датасет имеет особенности:\n",
    "- классы **несбалансированы** (доминирует `usa`),\n",
    "- есть пропуски (например, `horsepower`), требующие обработки.\n",
    "\n",
    "После предобработки (импутации и масштабирования для kNN) датасет корректно используется для сравнения kNN и дерева решений."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
